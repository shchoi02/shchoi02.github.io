---
title: ML Systems Problems Framing
date: 2025-08-23 11:45:58 +09:00
categories: ['mlops']
tags: ['mlops', 'ml systems', 'ml problems framing']
---

이 문서는 **《Designing Machine Learning Systems》** 책의 내용을 요약한 것입니다.

당신은 밀레니얼 세대를 타깃으로 하는 은행의 ML 엔지니어링 기술 리드라고 상상해봅니다. 어느 날, 상사가 경쟁 은행이 ML을 이용해 고객 서비스 지원을 두 배 빠르게 처리한다는 소식을 듣습니다. 
그는 당신의 팀에게도 ML을 이용해 고객 서비스 지원을 빠르게 할 방법을 찾으라고 지시합니다.

느린 고객 지원은 분명 문제이지만, 그것이 곧 ML 문제가 되는 것은 아닙니다. ML 문제는 입력, 출력, 그리고 학습 과정을 이끄는 목적 함수(objective function)로 정의됩니다. 
그러나 이 세 가지 구성 요소는 상사의 요청만으로는 명확하지 않습니다. 노련한 ML 엔지니어인 당신의 임무는 ML이 풀 수 있는 문제로 이 요청을 재구성하는 것입니다.

조사해 본 결과, 고객 요청에 대한 응답 지연의 병목은 고객 요청을 네 개 부서(회계, 재고, 인사, IT) 중 올바른 부서로 라우팅하는 과정에서 발생한다는 사실을 알게 되었습니다. 
이를 완화하기 위해, 어떤 부서로 요청을 보내야 하는지 예측하는 ML 모델을 개발할 수 있습니다. 이 문제는 분류 문제(classification problem)가 됩니다. 
입력은 고객 요청이고, 출력은 요청이 가야 할 부서입니다. 목적 함수는 예측된 부서와 실제 부서 간의 차이를 최소화하는 것입니다.

---

## ML 과업 유형 (Types of ML Tasks)

모델의 출력은 ML 문제의 과업(task) 유형을 결정합니다. 가장 일반적인 ML 과업 유형은 **분류(classification)** 와 **회귀(regression)** 입니다.

### 분류 vs 회귀
- **분류 모델**은 입력을 서로 다른 카테고리로 분류합니다. 예: 이메일을 스팸/비스팸으로 분류.
- **회귀 모델**은 연속적인 값을 출력합니다. 예: 집값을 예측.

회귀 문제는 분류 문제로 쉽게 변환될 수 있고, 그 반대도 가능합니다. 예를 들어, 집값 예측을 특정 구간(10만 달러 이하, 10만~20만 달러, 20만~50만 달러 등)으로 나누면 분류 문제가 됩니다. 
반대로 이메일 분류를 0과 1 사이의 값으로 출력하고, 0.5 이상이면 스팸으로 판정하면 회귀 문제로 볼 수도 있습니다.

---

### 이진 분류 vs 다중 클래스 분류
- **이진 분류(binary classification)**: 두 가지 클래스만 있는 경우. 예: 댓글이 독성인지 여부, 폐 CT에서 암 여부, 거래가 사기인지 여부.
- **다중 클래스 분류(multiclass classification)**: 세 개 이상의 클래스가 있는 경우. 예: 환자 진단(수천 개의 질병 클래스), 제품 분류(수만 개의 제품).

클래스 수가 많아질수록 **고유도(cardinality)** 가 높아지고, 데이터 수집과 학습이 매우 어려워집니다. 보통 한 클래스당 최소 100개의 예제가 필요하기 때문에, 1000개의 클래스가 있다면 최소 10만 개의 예제가 필요합니다. 이때 계층적 분류(hierarchical classification)가 유용할 수 있습니다.

---

### 다중 클래스 vs 다중 레이블 분류
- **다중 클래스(multiclass)**: 예제가 정확히 하나의 클래스에만 속합니다.
- **다중 레이블(multilabel)**: 예제가 여러 클래스에 동시에 속할 수 있습니다. 예: 기사 분류에서 "기술 + 금융".

멀티레이블 문제는 특히 어렵습니다.
- 라벨링 과정에서 주석자 간 불일치가 발생하기 쉽습니다.
- 예측 확률을 어떻게 해석할지 모호합니다 (상위 2개만 선택? 상위 3개?).

---

## 문제 프레이밍 방식의 차이

같은 문제라도 프레이밍에 따라 난이도가 달라집니다.

예: 사용자가 다음에 열 앱을 예측하기
- **단순 접근**: 다중 클래스 분류 (앱 N개 중 하나 선택). → 새 앱이 추가되면 모델을 다시 학습해야 함.
- **개선된 접근**: 회귀 문제로 프레이밍 (앱마다 0~1 점수를 예측). → 새 앱이 생겨도 입력에 새 앱의 특징만 넣으면 됨.

---

## 목적 함수 (Objective Functions)

ML 모델은 학습을 이끄는 **목적 함수(= 손실 함수)** 가 필요합니다. 예:
- **회귀**: RMSE, MAE
- **이진 분류**: 로지스틱 손실(logistic loss, log loss)
- **다중 클래스 분류**: 교차 엔트로피(cross entropy)

예: 정치 기사 분류 문제에서 실제 레이블 `[0,0,0,1]`인데 모델이 `[0.45, 0.2, 0.02, 0.33]`을 출력했다면, 교차 엔트로피 손실을 계산합니다.

```python
import numpy as np
def cross_entropy(p, q):
    return -sum([p[i] * np.log(q[i]) for i in range(len(p))])

p = [0, 0, 0, 1]
q = [0.45, 0.2, 0.02, 0.33]
cross_entropy(p, q)
```

---

## 다중 목적 최적화 (Decoupling Objectives)

문제를 여러 목적 함수로 정의해야 할 경우가 있습니다. 예: 뉴스피드 추천
- 원래 목표: 참여도(engagement) 극대화
- 추가 목표: 스팸/NSFW/가짜 뉴스 필터링, 품질 높은 게시물 우선

여러 목적이 충돌할 수 있습니다. (참여도↑ vs 품질↓)
- **방법 1**: 하나의 손실 함수로 결합
  ```
  loss = α * quality_loss + β * engagement_loss
  ```
- **방법 2**: 모델을 분리하여 각각 최적화 후, 결과를 가중합
  ```
  α * quality_score + β * engagement_score
  ```

목표를 분리하면 모델 유지 보수와 조정이 더 쉬워집니다.

---

## 데이터 vs 아이디어 (Mind Versus Data)

최근 ML의 성공은 **데이터의 품질과 양**에 크게 좌우되었습니다.
- **Mind-over-data 진영**: 구조적 설계와 귀납적 편향을 강조 (Judea Pearl, Chris Manning 등).
- **Data-over-mind 진영**: 더 많은 데이터와 계산 자원에 의존 (Rich Sutton, Peter Norvig 등).

예: Google 검색은 더 나은 알고리즘 때문이 아니라 **더 많은 데이터** 덕분에 성공했다고 Peter Norvig은 설명했습니다.

Monica Rogati의 "AI 필요 계층 구조(AI Hierarchy of Needs)"에 따르면, 데이터 과학의 기초는 결국 **데이터 자체**입니다.

---

## 맺음말

> ML 문제를 프레이밍하는 것은 단순히 모델을 적용하는 것이 아니라, 어떤 입력과 출력, 목적 함수를 정의할지 결정하는 과정입니다. 
> 같은 문제라도 어떻게 정의하느냐에 따라 난이도와 해법이 달라집니다.

> 데이터와 아이디어 중 어디에 초점을 둘지에 따라 접근 방식이 달라질 수 있습니다. 
> 현재까지의 흐름은 데이터의 품질과 양이 ML 성공의 핵심임을 보여줍니다.
> ML 엔지니어는 문제를 올바르게 프레이밍하고, 적절한 목적 함수를 선택하며, 무엇보다 데이터의 중요성을 인식하는 태도를 가져야 합니다.
